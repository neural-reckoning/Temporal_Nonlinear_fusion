{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sliding window and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import choice, rand, randn\n",
    "import numpy as np\n",
    "import lea  # probability calculations, see https://pypi.org/project/lea/\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import contourpy as cp\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[211  63 112  82 242  53 117  53  67]\n",
      " [ 10  88   8  79 638  90  15  62  10]\n",
      " [ 10  78   6  82 657  77   6  74  10]\n",
      " [  8  90  10  90 624  77  15  80   6]\n",
      " [  8  67  11  86 642  89  17  72   8]] 9\n",
      "[[410. 358. 231.   0.   0.   0.   0.   0.   0.]\n",
      " [104. 787. 108.   0.   0.   0.   0.   0.   0.]\n",
      " [ 98. 808.  93.   0.   0.   0.   0.   0.   0.]\n",
      " [113. 793.  93.   0.   0.   0.   0.   0.   0.]\n",
      " [111. 781. 107.   0.   0.   0.   0.   0.   0.]] 9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from multisensory_playbook import DetectionTask, DetectionTask_Etrans_test, Trials, LinearClassifier\n",
    "#from multisensory_playbook import detection_params_search_test, create_sliding_window_features\n",
    "\n",
    "\n",
    "nb_steps = 1000\n",
    "pm = 0.2 # smaller doesnt mean sparser signals from prey !!!!!!!!\n",
    "pe = 0.6 # for first value of E\n",
    "pn = 0.2 # smaller = less noisy (more zeros)\n",
    "pc = 0.6 #0.3\n",
    "pi = 0.3 #0.6 \n",
    "repeats = 5\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Borrow code from multisensory_playbook for debugging Trial.counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Task:\n",
    "    @property\n",
    "    def random_variables(self):\n",
    "        return NotImplemented\n",
    "\n",
    "    def generate_trials(self, repeats, time_steps, random_seed=None):\n",
    "        if random_seed is not None:\n",
    "            random.seed(random_seed)  # Set the random seed if provided\n",
    "        # random variables\n",
    "        rv = self.random_variables\n",
    "        M = rv[\"M\"]\n",
    "        A = rv[\"A\"]\n",
    "        V = rv[\"V\"]\n",
    "        # cache calculated joint distribution\n",
    "        joint_dists = {}\n",
    "        for m in [-1, 0, 1]:\n",
    "            if lea.P(M == m) == 0:\n",
    "                continue\n",
    "            joint_dists[m] = lea.joint(A, V).given(M == m).calc()\n",
    "        # generate true target values\n",
    "        arr_M = np.array(M.random(repeats))\n",
    "        steps = np.array(\n",
    "            [joint_dists[m].random(time_steps) for m in arr_M]\n",
    "        )  # steps has shape (repeats, time_steps, 2)\n",
    "        if time_steps == 0:\n",
    "            # print(steps.shape)\n",
    "            return Trials(\n",
    "                repeats=repeats,\n",
    "                time_steps=time_steps,\n",
    "                task=self,\n",
    "                M=arr_M,\n",
    "                A=steps[:, None],\n",
    "                V=steps[:, None],\n",
    "            )\n",
    "        else:\n",
    "            return Trials(\n",
    "                repeats=repeats,\n",
    "                time_steps=time_steps,\n",
    "                task=self,\n",
    "                M=arr_M,\n",
    "                A=steps[:, :, 0],\n",
    "                V=steps[:, :, 1],\n",
    "            )\n",
    "\n",
    "    @property\n",
    "    def baseline(self):\n",
    "        if not hasattr(self, \"_baseline\"):\n",
    "            M = self.random_variables[\"M\"]\n",
    "            self._baseline = max([lea.P(M == m) for m in [-1, 0, 1]])\n",
    "        return self._baseline\n",
    "\n",
    "    def baseline_reward(self, reward):\n",
    "        M = self.random_variables[\"M\"]\n",
    "        probs = np.array([lea.P(M == m) for m in [-1, 0, 1]])\n",
    "        expected_rewards = np.einsum(\"m,mg->g\", probs, reward)\n",
    "        return np.max(expected_rewards)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DetectionTask(Task):\n",
    "    pm: float\n",
    "    pe: float\n",
    "    pn: float\n",
    "    pc: float\n",
    "    pi: float\n",
    "\n",
    "    @property\n",
    "    def random_variables(self, random_seed=None):\n",
    "        if hasattr(self, \"_random_vars\"):\n",
    "            return self._random_vars\n",
    "        if random_seed is not None:\n",
    "            random.seed(random_seed)  # Set the random seed if provided\n",
    "    \n",
    "        target = lea.pmf({-1: self.pm * 0.5, 1: self.pm * 0.5, 0: 1 - self.pm})\n",
    "        emit_if_target = lea.event(self.pe)\n",
    "        emit_if_no_target = lea.event(0.0)\n",
    "        emit = target.switch(\n",
    "            {-1: emit_if_target, 1: emit_if_target, 0: emit_if_no_target}\n",
    "        )\n",
    "        signal_dist = {\n",
    "            (-1, True): lea.pmf({-1: self.pc, +1: self.pi, 0: 1 - self.pc - self.pi}),\n",
    "            (+1, True): lea.pmf({+1: self.pc, -1: self.pi, 0: 1 - self.pc - self.pi}),\n",
    "            (0, True): lea.pmf({-1: 0, +1: 0, 0: 1.0}),  # cannot happen\n",
    "            (-1, False): lea.pmf({-1: self.pn * 0.5, 1: self.pn * 0.5, 0: 1 - self.pn}),\n",
    "            (0, False): lea.pmf({-1: self.pn * 0.5, 1: self.pn * 0.5, 0: 1 - self.pn}),\n",
    "            (+1, False): lea.pmf({-1: self.pn * 0.5, 1: self.pn * 0.5, 0: 1 - self.pn}),\n",
    "        }\n",
    "        signal = lea.joint(target, emit).switch(signal_dist)\n",
    "        signal_A, signal_V = signal.clone(n=2, shared=(target, emit))\n",
    "        self._random_vars = {\"M\": target, \"E\": emit, \"A\": signal_A, \"V\": signal_V}\n",
    "        return self._random_vars\n",
    "    \n",
    "@dataclass\n",
    "class Trials:\n",
    "    repeats: int\n",
    "    time_steps: int\n",
    "    M: np.ndarray\n",
    "    A: np.ndarray\n",
    "    V: np.ndarray\n",
    "    task: Task\n",
    "\n",
    "    \"\"\"\n",
    "    # Has been re-implemented to incorporate sliding window functionality\n",
    "    def counts(self, pairs=True):\n",
    "        A = self.A\n",
    "        V = self.V\n",
    "        if self.time_steps == 0:\n",
    "            return np.zeros((self.repeats, 6 + 3 * pairs))\n",
    "        if pairs:\n",
    "            AV = (A + 1) + 3 * (V + 1)  # shape (repeats, time_steps)\n",
    "            C = np.apply_along_axis(np.bincount, 1, AV, minlength=9)  # (repeats, 9)\n",
    "        else:\n",
    "            CA = np.apply_along_axis(np.bincount, 1, A + 1, minlength=3)  # (repeats, 3)\n",
    "            CV = np.apply_along_axis(np.bincount, 1, V + 1, minlength=3)  # (repeats, 3)\n",
    "            C = np.concatenate((CA, CV), axis=1)\n",
    "        return C\n",
    "    \"\"\"\n",
    "    # Re-implementation of counts to incorporate sliding window functionality \n",
    "    def counts(self, windowsize=3, pairs=1): # pairs = 2 implemented!\n",
    "        A = self.A\n",
    "        V = self.V\n",
    "        #print(type(A))\n",
    "\n",
    "        def calculate_state(draw_sequence):\n",
    "            # Mapping for the states to digits\n",
    "            state_to_digit = {-1: 0, 0: 1, 1: 2} # To change -1 to 1\n",
    "            \n",
    "            # Convert the draw sequence to a base-3 number\n",
    "            base_3_number = 0\n",
    "            for draw in draw_sequence:\n",
    "                base_3_number = base_3_number * 3 + state_to_digit[draw]\n",
    "            #print(draw_sequence, base_3_number)\n",
    "\n",
    "            # The state is the base-3 number\n",
    "            return base_3_number\n",
    "\n",
    "        def apply_state(row):\n",
    "            # Convert row to list and pass it to the calculate_state function\n",
    "            #print(row.tolist())\n",
    "            return calculate_state(row.tolist())\n",
    "        \n",
    "        if self.time_steps == 0:\n",
    "            return np.zeros((self.repeats, 6 + 3 * pairs))\n",
    "        \n",
    "        if pairs == 0:\n",
    "            CA = np.apply_along_axis(np.bincount, 1, A + 1, minlength=3)  # (repeats, 3)\n",
    "            CV = np.apply_along_axis(np.bincount, 1, V + 1, minlength=3)  # (repeats, 3)\n",
    "            C = np.concatenate((CA, CV), axis=1)\n",
    "\n",
    "        elif pairs == 1:\n",
    "            AV = (A + 1) + 3 * (V + 1)  # shape (repeats, time_steps)\n",
    "            C = np.apply_along_axis(np.bincount, 1, AV, minlength=9)  # (repeats, 9)     \n",
    "\n",
    "        elif pairs == 2: # consider windows with n number of consecutive AV-pairs\n",
    "            max_state = 3**(2*windowsize) # 3**(2n) \n",
    "            C = np.zeros((self.repeats, max_state))\n",
    "            for trialnum in range(self.repeats):\n",
    "                #print(trialnum)\n",
    "                _A = A[trialnum]\n",
    "                _V = V[trialnum]\n",
    "                #print(A.shape)\n",
    "                df = pd.DataFrame()\n",
    "                df['A'], df['V'] = _A, _V\n",
    "                \n",
    "                if windowsize == 2:\n",
    "                    df['A-1'], df['V-1'] =  df['A'].shift(1), df['V'].shift(1) # Shifting column down one step\n",
    "                if windowsize == 3:\n",
    "                    df['A-1'], df['V-1'] =  df['A'].shift(1), df['V'].shift(1) # Shifting column down one step\n",
    "                    df['A-2'], df['V-2'] =  df['A'].shift(2), df['V'].shift(2) # Shifting column down one step (window size is 3)\n",
    "                df = df.dropna()\n",
    "                #print(df)\n",
    "                #return df\n",
    "                \n",
    "                # Apply the function to each row and store the result in a new column 'state'\n",
    "                df['state'] = df.apply(apply_state, axis=1)\n",
    "                # Calculate value counts\n",
    "                state_counts = df['state'].value_counts()\n",
    "                \n",
    "\n",
    "                # Generate a range of numbers representing all possible states\n",
    "                # Adjust the range based on your specific needs (max_state + 1)\n",
    "                \n",
    "                all_possible_states = range(0, max_state)  # Replace max_state with your actual maximum state value\n",
    "\n",
    "                # Reindex the value counts to include all possible states\n",
    "                # Fill missing values (states with 0 occurrences) with 0\n",
    "                state_counts = state_counts.reindex(all_possible_states, fill_value=0)\n",
    "                #return state_counts\n",
    "                \n",
    "                #state_counts = state_counts.values.reshape(1,-1)\n",
    "                C[trialnum,:] = state_counts\n",
    "                \n",
    "                #return state_counts\n",
    "\n",
    "        return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = DetectionTask(pm=pm, pe=pe, pn=pn, pc=pc, pi=pi)\n",
    "trials = task.generate_trials(time_steps=200, repeats=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "C0 = (trials.counts(pairs=0)) \n",
    "C1 = (trials.counts(pairs=1))\n",
    "C2 = (trials.counts(windowsize=3, pairs=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 9)\n",
      "(1, 729)\n"
     ]
    }
   ],
   "source": [
    "print(C1.shape)\n",
    "print(C2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "198.0\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(C1[0]))\n",
    "print(np.sum(C2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 9)"
      ]
     },
     "execution_count": 744,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version without sliding window generator, try to add this functionality within Trials.counts()\n",
    "\n",
    "# Expand the detection params search to include handling of sliding window features\n",
    "def detection_params_search_test(p_ranges, nb_trials, nb_steps, tasktype='DetectionTask', trans_prob=None, window_size=2, random_seed=None):\n",
    "    #classifier_type = LinearClassifier #MAPClassifier ### TEST\n",
    "    #print('test')\n",
    "    # Sample task parameters\n",
    "    while True:\n",
    "        \n",
    "        p = {\n",
    "            k: rand() * (upper - lower) + lower\n",
    "            for k, (lower, upper) in p_ranges.items()\n",
    "        }\n",
    "        # Add debugging prints for parameter values\n",
    "        #print(\"Sampled parameters:\", p)\n",
    "\n",
    "        if p[\"pc\"] <= 0.5 * p[\"pn\"]:\n",
    "            continue\n",
    "        if p[\"pi\"] >= p[\"pc\"]:\n",
    "            continue\n",
    "        if p[\"pi\"] >= 0.5 * p[\"pn\"]:\n",
    "            continue\n",
    "        if p[\"pi\"] + p[\"pc\"] <= p[\"pn\"]:\n",
    "            continue\n",
    "        if p[\"pc\"] + p[\"pi\"] > 1.0:\n",
    "            continue\n",
    "        break\n",
    "    #print(p)\n",
    "    # Generate trials\n",
    "    if tasktype == 'DetectionTask':\n",
    "        task = DetectionTask(**p)\n",
    "        full_trials = task.generate_trials(nb_trials, nb_steps, random_seed=random_seed)\n",
    "        #print(\"Generated trials with DetectionTask\", full_trials) ### TEST\n",
    "        \n",
    "    elif tasktype == 'DetectionTask_Etrans_test':\n",
    "        p['nb_repeats'] = nb_trials\n",
    "        p['nb_steps'] = nb_steps\n",
    "        if trans_prob:\n",
    "            p['trans_prob'] = trans_prob[0] \n",
    "        task = DetectionTask_Etrans_test(**p, random_seed=random_seed) \n",
    "        full_trials = task.generate_trials\n",
    "        #print(\"Generated trials with DetectionTask_Etrans_test\", full_trials) ### TEST\n",
    "        # Reset p\n",
    "        keys_to_remove = {'nb_repeats', 'nb_steps', 'trans_prob'}\n",
    "        p = dict(filter(lambda item: item[0] not in keys_to_remove, p.items()))\n",
    "    \n",
    "    # Train-test trials :Generate test data separately\n",
    "    training_size = nb_trials\n",
    "    testing_size = nb_trials\n",
    "    training_trials = Trials(\n",
    "        repeats=training_size,\n",
    "        time_steps=nb_steps,\n",
    "        M=full_trials.M,\n",
    "        A=full_trials.A,\n",
    "        V=full_trials.V,\n",
    "        task=task\n",
    "    )\n",
    "\n",
    "    testing_trials = Trials(\n",
    "        repeats=testing_size,\n",
    "        time_steps=nb_steps,\n",
    "        M=full_trials.M,\n",
    "        A=full_trials.A,\n",
    "        V=full_trials.V,\n",
    "        task=task\n",
    "    )\n",
    "\n",
    "   \n",
    "    # Calculate accuracy\n",
    "    accs_tmp = []\n",
    "\n",
    "    for pairs in [0, 1, 2]:\n",
    "        #print(pairs)\n",
    "        # Check if there is only one class in training data. If yes, skip \n",
    "        unique_classes_train = np.unique(training_trials.M)\n",
    "        unique_classes_test = np.unique(testing_trials.M)\n",
    "        if len(unique_classes_train) == 1:\n",
    "            #print(f\"Skipping training and testing: Only one class ({unique_classes_train[0]}) in training data.\")\n",
    "            #print(f\"Params: {p}\")\n",
    "            #accs_tmp.append([])  # Append None or a default value to indicate skipping\n",
    "            print('train classes = 1')\n",
    "            return [0.0, 0.0, 0.0], np.array(list(p.values())) * 0.0 # function exits here\n",
    "            \n",
    "        if len(unique_classes_test) == 1:\n",
    "            #print(f\"Skipping training and testing: Only one class ({unique_classes_test[0]}) in test data.\")\n",
    "            #print(f\"Params: {p}\")\n",
    "            \n",
    "            return [0.0, 0.0, 0.0], np.array(list(p.values())) * 0.0\n",
    "\n",
    "        classifier = LinearClassifier(task, pairs=pairs)\n",
    "\n",
    "        # Train and test the classifier using sliding window features\n",
    "        trained_classifier = classifier.train(training_trials)\n",
    "        res = trained_classifier.test(testing_trials)\n",
    "        accs_tmp.append(res.accuracy)\n",
    "\n",
    "    # Filter for accuracy\n",
    "    _, a = np.unique(full_trials.M, return_counts=True)  # majority class classifier\n",
    "    a = a.max() / a.sum()\n",
    "    w = 1 - a\n",
    "    c = (1 + a) / 2\n",
    "    #print(c - w / 2 * 0.05, c + w / 2 * 0.05) ### TEST\n",
    "    #return accs_tmp, np.array(list(p.values())) ### TEST: ignore the condition of return for testing \n",
    "    \n",
    "    if (max(accs_tmp) > (c - w / 2 * 0.75)) & (min(accs_tmp) < (c + w / 2 * 0.75)): # 0.75\n",
    "        return accs_tmp, np.array(list(p.values()))\n",
    "    else:\n",
    "        #print('else')\n",
    "        return [0.0, 0.0, 0.0], np.array(list(p.values())) * 0.0 # three elements in returned list since now we have 3 values for pairs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_ranges = {\n",
    "    \"pm\": (0.0, 1.0),  # p of motion\n",
    "    \"pe\": (0.0, 1.0),  # p of emitting given there is motion\n",
    "    \"pc\": (0.0, 1.0),  # p correct direction when emitting\n",
    "    \"pn\": (0.0, 1.0),  # p not neutral when not emitting\n",
    "    \"pi\": (0.0, 0.5),  # p incorrect when emitting\n",
    "}\n",
    "p_labels = [\"$p_m$\", \"$p_e$\", \"$p_c$\", \"$p_n$\", \"$p_i$\"]\n",
    "\n",
    "nb_trials = 100# original: 10000\n",
    "nb_steps = 100 # original: 90\n",
    "search_size = 10000 # original: 10000\n",
    "# probability of transitioning from e_current to e_next\n",
    "trans_prob = {\n",
    "    0: [0.5, 0.5],  # Probabilities for transitioning from E=0\n",
    "    1: [0.5, 0.5],  # Probabilities for transitioning from E=1\n",
    "}\n",
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'full_trials' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[813], line 4\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i, detection_params_search_test(p_ranges, nb_trials, nb_steps, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDetectionTask_Etrans\u001b[39m\u001b[38;5;124m'\u001b[39m, (trans_prob, ), random_seed\u001b[38;5;241m==\u001b[39mrandom_seed))\n",
      "Cell \u001b[1;32mIn[810], line 53\u001b[0m, in \u001b[0;36mdetection_params_search_test\u001b[1;34m(p_ranges, nb_trials, nb_steps, tasktype, trans_prob, window_size, random_seed)\u001b[0m\n\u001b[0;32m     48\u001b[0m training_size \u001b[38;5;241m=\u001b[39m nb_trials\n\u001b[0;32m     49\u001b[0m testing_size \u001b[38;5;241m=\u001b[39m nb_trials\n\u001b[0;32m     50\u001b[0m training_trials \u001b[38;5;241m=\u001b[39m Trials(\n\u001b[0;32m     51\u001b[0m     repeats\u001b[38;5;241m=\u001b[39mtraining_size,\n\u001b[0;32m     52\u001b[0m     time_steps\u001b[38;5;241m=\u001b[39mnb_steps,\n\u001b[1;32m---> 53\u001b[0m     M\u001b[38;5;241m=\u001b[39mfull_trials\u001b[38;5;241m.\u001b[39mM,\n\u001b[0;32m     54\u001b[0m     A\u001b[38;5;241m=\u001b[39mfull_trials\u001b[38;5;241m.\u001b[39mA,\n\u001b[0;32m     55\u001b[0m     V\u001b[38;5;241m=\u001b[39mfull_trials\u001b[38;5;241m.\u001b[39mV,\n\u001b[0;32m     56\u001b[0m     task\u001b[38;5;241m=\u001b[39mtask\n\u001b[0;32m     57\u001b[0m )\n\u001b[0;32m     59\u001b[0m testing_trials \u001b[38;5;241m=\u001b[39m Trials(\n\u001b[0;32m     60\u001b[0m     repeats\u001b[38;5;241m=\u001b[39mtesting_size,\n\u001b[0;32m     61\u001b[0m     time_steps\u001b[38;5;241m=\u001b[39mnb_steps,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     65\u001b[0m     task\u001b[38;5;241m=\u001b[39mtask\n\u001b[0;32m     66\u001b[0m )\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# Calculate accuracy\u001b[39;00m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: cannot access local variable 'full_trials' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for i in range(1, 10):\n",
    "    print(i, detection_params_search_test(p_ranges, nb_trials, nb_steps, 'DetectionTask', (trans_prob, ), random_seed==random_seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 82)"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
