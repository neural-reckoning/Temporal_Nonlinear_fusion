{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb376b55-7a7a-46ba-bffd-4c5ae6153730",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eed3b94b-6939-47ff-a3ac-3e5f05868eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "bf3538c7-00be-4cdc-b4a0-ee071f9291dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color definitions\n",
    "color_LF = 'xkcd:muted blue'\n",
    "color_NLF = 'xkcd:coral pink'\n",
    "color_NLF2 = 'goldenrod'\n",
    "color_NLF3 = 'xkcd:sage green'\n",
    "color_RNN = 'xkcd:muted purple'\n",
    "\n",
    "plt.rcParams.update({\n",
    "    # Your existing font parameters\n",
    "    'font.size': 14,\n",
    "    'axes.titlesize': 30,\n",
    "    'axes.labelsize': int(40 * 1.3),\n",
    "    'xtick.labelsize': 35,\n",
    "    'ytick.labelsize': 35,\n",
    "    'legend.fontsize': 30,\n",
    "    'legend.title_fontsize': 30,\n",
    "    'axes.labelweight': 'bold',\n",
    "    \n",
    "    # Tripled axes linewidth (from 1.5 to 4.5)\n",
    "    'axes.linewidth': 5,\n",
    "    \n",
    "    # Doubled plot line width (from 4 to 8)\n",
    "    'lines.linewidth': 8,\n",
    "    \n",
    "    # Doubled grid linewidth (from 0.5)\n",
    "    'grid.linewidth': 2.0,\n",
    "    \n",
    "    # Your other existing parameters\n",
    "    'figure.figsize': (10, 6),\n",
    "    'figure.dpi': 100,\n",
    "    \n",
    "    'xtick.major.size': 5,\n",
    "    'xtick.minor.size': 3,\n",
    "    'ytick.major.size': 5,\n",
    "    'ytick.minor.size': 3,\n",
    "    'xtick.major.width': 1.5,\n",
    "    'xtick.minor.width': 1,\n",
    "    'ytick.major.width': 1.5,\n",
    "    'ytick.minor.width': 1,\n",
    "    'xtick.direction': 'out',\n",
    "    'ytick.direction': 'out',\n",
    "    \n",
    "    'grid.alpha': 0.3,\n",
    "    'lines.markersize': 8,\n",
    "    \n",
    "    'font.family': 'sans-serif',\n",
    "    'font.sans-serif': ['Arial', 'Helvetica', 'DejaVu Sans'],\n",
    "    \n",
    "    'legend.framealpha': 0.8,\n",
    "    'legend.edgecolor': '0.8',\n",
    "    \n",
    "    'figure.autolayout': True,\n",
    "    \n",
    "    'savefig.dpi': 300,\n",
    "    'savefig.format': 'png',\n",
    "    \n",
    "    'axes.grid': True,\n",
    "    'axes.axisbelow': True,\n",
    "})\n",
    "\n",
    "plt.rcParams['legend.frameon'] = False\n",
    "plt.rcParams['axes.spines.top'] = False\n",
    "plt.rcParams['axes.spines.right'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ee6326-ee38-492c-a1b0-83031a4d8539",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d7ad43-bdfb-4fde-aec6-101da6db3c08",
   "metadata": {},
   "source": [
    "**Data description:**\n",
    "\n",
    "  *RNN*\n",
    "- format: dictionary\n",
    "- key:   tuple (training choice, testing choice)\n",
    "- value: testing accuracy\n",
    "\n",
    "*NLF_k*\n",
    "- format: dictionary\n",
    "- key:  tuple (training choice, NLF window size, testing choice)\n",
    "- value:  testing accuracy\n",
    "\n",
    "*Ranges*\n",
    "- training choice: [1,8]\n",
    "- testing choice: [1,8]\n",
    "- NLF window size: 2,3\n",
    "- time steps: 500\n",
    "\n",
    "*Experiment types*\n",
    "- Levy\n",
    "- Levy equal distribution of probabilities of all k values\n",
    "- Non-Levy (nomenclature does not specify as non-Levy, for eg. classifier_accuracies_500steps.pkl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccd9c65-0d56-4ee8-ab53-77b54ea61ee4",
   "metadata": {},
   "source": [
    "#### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "90be0441-05e2-42ed-9a9e-00081b18e22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_path = os.path.join(os.getcwd(), 'RNN')\n",
    "NLFw_path = os.path.join(os.getcwd(), 'NLFw')\n",
    "NLF_path = os.path.join(os.getcwd(), 'NLF')\n",
    "LF_path = os.path.join(os.getcwd(), 'LF')\n",
    "seeds = [1000, 2000, 3000, 4000, 5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "856f21bf-ed4a-4950-930c-6cc8d2b557b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom exception when file is not found\n",
    "class NoFilesFoundError(Exception):\n",
    "    \"\"\"Exception raised when no fusion run files are found.\"\"\"\n",
    "    pass\n",
    "    \n",
    "def load_rnn_accuracies(base_path=RNN_path, seeds=[1000, 2000, 3000, 4000, 5000], steps=500, k_range=range(1, 9), include_levy=False, eql_distr=False, stats=False):\n",
    "    \"\"\"\n",
    "    Load RNN accuracies from pickle files and summarize the results.\n",
    "\n",
    "    This function loads RNN accuracy data from pickle files, either for regular k-based (i.e., Non-Levy) files\n",
    "    or Levy-based files, depending on the parameters. It then summarizes the data using the\n",
    "    RNN_summary function.\n",
    "\n",
    "    Args:\n",
    "        base_path (str): The base path where the RNN files are stored. Default is RNN_path.\n",
    "        seeds (list): A list of random seeds used in the RNN training. Default is [1000, 2000, 3000, 4000, 5000].\n",
    "        steps (int): The number of steps used in the RNN training and testing. Default is 500.\n",
    "        k_range (range): The range of k values to consider for regular k-based files. Default is range(1, 9).\n",
    "        include_levy (bool): If True, load Levy-based files instead of regular k-based files. Default is False.\n",
    "        eql_distr (bool): If True and include_levy is True, load equal distribution Levy files. Default is False.\n",
    "        stats (bool): If True, include statistical analysis in the summary. Default is False.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing the summarized RNN accuracy data.\n",
    "\n",
    "    Raises:\n",
    "        NoFilesFoundError: If no matching RNN files are found in the specified path.\n",
    "    \"\"\"\n",
    "\n",
    "    #print(f\"Debug: include_levy is {include_levy}\")  # Debug print\n",
    "    all_runs = {}\n",
    "    \n",
    "    if not include_levy:\n",
    "        print(\"Loading non-Levy files\")  # Debug print\n",
    "        # Regular k-based files\n",
    "        for seed in seeds:\n",
    "            for k in k_range:\n",
    "                file_path = os.path.join(base_path, f'RNN_train_k_{k}_seed_{seed}_{steps}steps_testaccuracies.pkl')\n",
    "                if os.path.exists(file_path):\n",
    "                    with open(file_path, 'rb') as file:\n",
    "                        data = pkl.load(file)\n",
    "                        \n",
    "                        for key, value in data.items():\n",
    "                            if key not in all_runs:\n",
    "                                all_runs[key] = []\n",
    "                            all_runs[key].append(value)\n",
    "                else:\n",
    "                    raise NoFilesFoundError(f\"No file found in {base_path} with seed={seed} and steps={steps}\")              \n",
    "    \n",
    "    else:\n",
    "        print(\"Loading Levy files\")  # Debug print\n",
    "        # Levy files\n",
    "        for seed in seeds:\n",
    "            if eql_distr:\n",
    "                if seed == 1000:\n",
    "                    print(\"Loading equal distribution k Levy files\")  # Debug print\n",
    "                file_path = os.path.join(base_path, f'RNN_train_levy_seed_{seed}_{steps}steps_eqldistr_k_testaccuracies.pkl')\n",
    "            else:\n",
    "                file_path = os.path.join(base_path, f'RNN_train_levy_seed_{seed}_{steps}steps_testaccuracies.pkl')\n",
    "            \n",
    "            if os.path.exists(file_path):\n",
    "                with open(file_path, 'rb') as file:\n",
    "                    data = pkl.load(file)\n",
    "                    \n",
    "                    for key, value in data.items():\n",
    "                        if key not in all_runs:\n",
    "                            all_runs[key] = []\n",
    "                        all_runs[key].append(value)\n",
    "            else:\n",
    "                raise NoFilesFoundError(f\"No file found in {base_path} with seed={seed} and steps={steps}\")\n",
    "    \n",
    "    print(f\"Number of items in all_runs: {len(all_runs)}\")  # Debug print\n",
    "    df = RNN_summary(all_runs, stats)\n",
    "    return df\n",
    "\n",
    "\n",
    "def RNN_summary(datadict, stats=False):\n",
    "    \"\"\"\n",
    "    Summarize RNN accuracy data and optionally calculate statistics.\n",
    "\n",
    "    This function takes a dictionary of RNN accuracy data and converts it into a pandas DataFrame.\n",
    "    If stats is True, it calculates mean and standard deviation of accuracies for each train-test pair.\n",
    "\n",
    "    Args:\n",
    "        datadict (dict): A dictionary containing RNN accuracy data.\n",
    "            The keys are tuples of (train, test), and the values are lists of accuracies.\n",
    "        stats (int): If True, calculate and return statistics. Otherwise, return the raw data. Default is False.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing either the raw accuracy data or summary statistics,\n",
    "                          depending on the value of the 'stats' parameter.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame([(k[0], k[1], v) for k, v in datadict.items()], \n",
    "                      columns=['train', 'test', 'accuracy'])\n",
    "    # Explode the accuracy list\n",
    "    df = df.explode('accuracy')\n",
    "    \n",
    "    if stats:\n",
    "        # Calculate statistics\n",
    "        stats_df = df.groupby(['train', 'test'])['accuracy'].agg(['mean', lambda x: np.std(x, ddof=1)]).reset_index()\n",
    "        stats_df.columns = ['train', 'test', 'mean_accuracy', 'std_accuracy']\n",
    "        return stats_df\n",
    "    else:\n",
    "        return df\n",
    "    \n",
    "\n",
    "def load_fusion_accuracies(base_path=NLFw_path, steps=500, k_range=range(1, 9), include_levy=False, eql_distr=False):\n",
    "    \"\"\"\n",
    "    Load NLFw (Non-Linear Fusion with sliding time windows), NLF or LF accuracies from pickle files and summarize the results.\n",
    "\n",
    "    This function loads accuracy data from a single pickle file, which can be either for regular k-based (i.e., Non-Levy) data,\n",
    "    Levy-based data, or equal distribution Levy-based data, depending on the parameters. It then summarizes the data\n",
    "    using the fusion_summary function.\n",
    "\n",
    "    Args:\n",
    "        base_path (str): The base path where the files are stored. Default is NLFw_path.\n",
    "        steps (int): The number of steps used in the fusion training. Default is 500.\n",
    "        k_range (range): The range of k values to consider. Default is range(1, 9). (Note: This parameter is unused in the function body)\n",
    "        include_levy (bool): If True, load Levy-based file instead of regular k-based file. Default is False.\n",
    "        eql_distr (bool): If True and include_levy is True, load equal distribution Levy file. Default is False.\n",
    "\n",
    "    Returns:\n",
    "        pandas.Dictionary: A Dictionary containing the summarized accuracy data.\n",
    "\n",
    "    Raises:\n",
    "        NoFilesFoundError: If no matching fusion file is found in the specified path.\n",
    "    \"\"\"\n",
    "\n",
    "    all_runs = {}\n",
    "    if not include_levy:\n",
    "        print(\"Loading non-Levy files\")  # Debug print\n",
    "        # Regular k-based files\n",
    "        file_path = os.path.join(base_path, f'classifier_accuracies_{steps}steps.pkl')\n",
    "    elif eql_distr:\n",
    "        file_path = os.path.join(base_path, f'classifier_accuracies_{steps}steps_levy_eqldistr_k.pkl')\n",
    "    else:\n",
    "        file_path = os.path.join(base_path, f'classifier_accuracies_{steps}steps_levy.pkl')\n",
    "        \n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'rb') as file:\n",
    "            data = pkl.load(file)\n",
    "            \n",
    "            for key, value in data.items():\n",
    "                if key not in all_runs:\n",
    "                    all_runs[key] = []\n",
    "                all_runs[key].append(value)\n",
    "            \n",
    "    else:\n",
    "        raise NoFilesFoundError(f\"No file found in {base_path} with steps={steps}\")     \n",
    "    print(f\"Number of items in all_runs: {len(all_runs)}\")  # Debug print\n",
    "    df = fusion_summary(all_runs)\n",
    "    return df\n",
    "\n",
    "    \n",
    "def fusion_summary(datadict, accuracy_mult_by_100=True):\n",
    "    \"\"\"\n",
    "    Summarize NLFw (Non-Linear Fusion with sliding time windows), NLF or LF accuracy data.\n",
    "\n",
    "    This function takes a dictionary of accuracy data, converts it into a pandas DataFrame,\n",
    "    and calculates accuracies for each combination of train, test, and window size. \n",
    "\n",
    "    Args:\n",
    "        datadict (dict): A dictionary containing accuracy data.\n",
    "            The keys are tuples of (train, windowsize, test), and the values are lists of accuracies.\n",
    "        accuracy_mult_by_100 (bool): If True, multiply the mean accuracy by 100. Default is True.\n",
    "    \n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are window sizes and values are pandas DataFrames.\n",
    "              Each DataFrame contains accuracies for the corresponding window size.\n",
    "    \"\"\"\n",
    "       \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame([(k[0], k[1], k[2], v) for k, v in datadict.items()], \n",
    "                      columns=['train', 'windowsize', 'test', 'accuracy'])\n",
    "    \n",
    "    # Explode the accuracy list\n",
    "    df = df.explode('accuracy')\n",
    "    \n",
    "    # Get unique window sizes\n",
    "    windowsizes = df['windowsize'].unique()\n",
    "    \n",
    "    # Split the DataFrame based on windowsize\n",
    "    dfs = {ws: df[df['windowsize'] == ws] for ws in windowsizes}\n",
    "    \n",
    "    # Calculate statistics for each split DataFrame\n",
    "    stats_dfs = {}\n",
    "    \n",
    "    for ws, split_df in dfs.items():\n",
    "        stats_df = split_df.groupby(['train', 'test'])['accuracy'].agg(['mean']).reset_index()\n",
    "        stats_df.columns = ['train', 'test', 'mean_accuracy']\n",
    "        if accuracy_mult_by_100:\n",
    "            stats_df['mean_accuracy'] *= 100\n",
    "        stats_df['std_accuracy'] = None # Required column for plotting functionality\n",
    "        stats_dfs[ws] = stats_df\n",
    "    return stats_dfs\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16232fd-a940-46a9-adaa-49ec3ec4421c",
   "metadata": {},
   "source": [
    "#### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b511ee81-ddb2-4020-b586-9995b53f4da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_nonlevy = load_rnn_accuracies(steps=500, include_levy=0, eql_distr=0, stats=1)\n",
    "#RNN_levy = load_rnn_accuracies(steps=500, include_levy=1, eql_distr=0, stats=1)\n",
    "#RNN_levy_eqldistr = load_rnn_accuracies(steps=500, include_levy=1, eql_distr=1, stats=1)\n",
    "\n",
    "NLFw_nonlevy = load_fusion_accuracies(steps=500, include_levy=0, eql_distr=0)\n",
    "#NLFw_levy = load_fusion_accuracies(steps=500, include_levy=1, eql_distr=0)\n",
    "#NLFw_levy_eqldistr = load_fusion_accuracies(steps=500, include_levy=1, eql_distr=1)\n",
    "\n",
    "LF_nonlevy = load_fusion_accuracies(base_path=LF_path, steps=500, include_levy=0, eql_distr=0)\n",
    "#LF_levy = load_fusion_accuracies(base_path=LF_path, steps=500, include_levy=1, eql_distr=0)\n",
    "#LF_levy_eqldistr = load_fusion_accuracies(base_path=LF_path, steps=500, include_levy=1, eql_distr=1)\n",
    "\n",
    "NLF_nonlevy = load_fusion_accuracies(base_path=NLF_path, steps=500, include_levy=0, eql_distr=0)\n",
    "#NLF_levy = load_fusion_accuracies(base_path=NLF_path, steps=500, include_levy=1, eql_distr=0)\n",
    "#NLF_levy_eqldistr = load_fusion_accuracies(base_path=NLF_path, steps=500, include_levy=1, eql_distr=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed41c60-fcd2-42ab-be40-2d99534a45b5",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1ebf0a",
   "metadata": {},
   "source": [
    "#### Train & Test with error bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "238d6ec9-60b8-46e9-8006-0d6c8122b09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all train-test scenarios with error bars\n",
    "def plot_with_error_bars(df, ax=None, title=None, label=None, color=None):\n",
    "    # Check if necessary columns exist\n",
    "    required_columns = ['test', 'mean_accuracy', 'train']\n",
    "    for col in required_columns:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"Column '{col}' not found in DataFrame\")\n",
    "    \n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    unique_trains = df['train'].unique()\n",
    "    print(unique_trains)\n",
    "    colors = plt.cm.plasma(np.linspace(0, 1, len(unique_trains)))\n",
    "    color_map = dict(zip(unique_trains, colors))\n",
    "    \n",
    "    for train_value in unique_trains:\n",
    "        subset = df[df['train'] == train_value]\n",
    "        \n",
    "        plot_color = color if color else color_map[train_value]\n",
    "        \n",
    "        # Plot the line first\n",
    "        ax.plot(subset['test'], subset['mean_accuracy'], \n",
    "                linestyle='-', \n",
    "                color=plot_color,\n",
    "                label=label if label else f'{train_value}')\n",
    "        \n",
    "        # Check if std_accuracy column exists and is not all None/NaN\n",
    "        if 'std_accuracy' in df.columns and not subset['std_accuracy'].isna().all():\n",
    "            ax.errorbar(subset['test'], subset['mean_accuracy'], \n",
    "                        yerr=subset['std_accuracy'],\n",
    "                        fmt='|', \n",
    "                        capsize=2,\n",
    "                        capthick=1,\n",
    "                        elinewidth=2,\n",
    "                        color=plot_color)\n",
    "    \n",
    "    ax.set_xlabel('Test')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "    #ax.grid(True)\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend(handles, labels, title='Train', ncol=2)\n",
    "    ax.set_ylim(76, 90)\n",
    "    return ax\n",
    "\n",
    "#plot_with_error_bars(RNN_nonlevy, title='RNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aefb985",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_diagonal_only(df, ax=None, title=None, label=None, color='grey'):\n",
    "    # Check if necessary columns exist\n",
    "    required_columns = ['test', 'mean_accuracy', 'train']\n",
    "    for col in required_columns:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"Column '{col}' not found in DataFrame\")\n",
    "    \n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    # Filter for diagonal data (train == test)\n",
    "    diagonal_df = df[df['train'] == df['test']].sort_values('train')\n",
    "    \n",
    "    # Plot diagonal line\n",
    "    ax.plot(diagonal_df['test'], diagonal_df['mean_accuracy'], \n",
    "            linestyle='-', \n",
    "            marker='o',\n",
    "            color=color,\n",
    "            linewidth=2,\n",
    "            label=label)\n",
    "    \n",
    "    # Add error bars if std_accuracy is available\n",
    "    if 'std_accuracy' in df.columns and not diagonal_df['std_accuracy'].isna().all():\n",
    "        ax.errorbar(diagonal_df['test'], diagonal_df['mean_accuracy'], \n",
    "                    yerr=diagonal_df['std_accuracy'],\n",
    "                    fmt='o', \n",
    "                    capsize=4,\n",
    "                    capthick=2,\n",
    "                    elinewidth=2,\n",
    "                    color=color)\n",
    "    \n",
    "    ax.set_xlabel('Train k == test k')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_title(title)\n",
    "    ax.legend(ncol=2)\n",
    "    ax.grid(True)\n",
    "    #ax.set_ylim(80, 90)\n",
    "    \n",
    "    # Set x-axis ticks to match the train/test values\n",
    "    ax.set_xticks(diagonal_df['test'])\n",
    "    ax.set_xticklabels(diagonal_df['test'])\n",
    "    \n",
    "    return ax\n",
    "\n",
    "\n",
    "color_LF = 'xkcd:muted blue'\n",
    "color_NLF = 'xkcd:coral pink'\n",
    "color_NLF2 = '#60AB9E'\n",
    "color_NLF3 = '#BEBC48'\n",
    "color_RNN = '#A778B4'\n",
    "\n",
    "# Usage example:\n",
    "ax = plot_diagonal_only(LF_nonlevy['LF'], label='LF', color='xkcd:muted blue')\n",
    "plot_diagonal_only(NLF_nonlevy['NLF_1'], ax=ax, label='NLF', color='xkcd:coral pink')\n",
    "plot_diagonal_only(NLFw_nonlevy[2], ax=ax, label='NLF 2', color='#60AB9E')\n",
    "plot_diagonal_only(NLFw_nonlevy[3], ax=ax, label='NLF 3', color='#BEBC48')\n",
    "plot_diagonal_only(RNN_nonlevy, ax=ax, label='RNN', color='#A778B4')\n",
    "plt.ylim(75, 90)\n",
    "#plt.yticks([75, 80, 85, 90])\n",
    "plt.savefig('Fig2A.svg', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea830ea",
   "metadata": {},
   "source": [
    "#### Train & Test with shaded regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a55f67a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_with_shaded_errors_all(df, ax=None, title='Accuracy', label=None, shade_color='blue', alpha=0.2, show_lines=False, show_markers=False, add_colorbar=True):\n",
    "    # Check if necessary columns exist\n",
    "    required_columns = ['test', 'mean_accuracy', 'train']\n",
    "    for col in required_columns:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"Column '{col}' not found in DataFrame\")\n",
    "    \n",
    "    # Ensure mean_accuracy is numeric\n",
    "    df['mean_accuracy'] = pd.to_numeric(df['mean_accuracy'], errors='coerce')\n",
    "    \n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    unique_trains = sorted(df['train'].unique())\n",
    "    \n",
    "    # Create a color map for the gradient\n",
    "    cmap = plt.cm.viridis\n",
    "    norm = plt.Normalize(vmin=min(unique_trains), vmax=max(unique_trains))\n",
    "    \n",
    "    # Sort the dataframe by train and test\n",
    "    df_sorted = df.sort_values(['train', 'test'])\n",
    "    \n",
    "    # Create shaded region between min and max accuracies\n",
    "    min_accuracies = df_sorted.groupby('test')['mean_accuracy'].min()\n",
    "    max_accuracies = df_sorted.groupby('test')['mean_accuracy'].max()\n",
    "    \n",
    "    ax.fill_between(min_accuracies.index, min_accuracies, max_accuracies,\n",
    "                    alpha=alpha, color='gray' if shade_color is None else shade_color, label=label)\n",
    "    \n",
    "    if show_lines or show_markers:\n",
    "        for train_value in unique_trains:\n",
    "            subset = df_sorted[df_sorted['train'] == train_value]\n",
    "            plot_color = cmap(norm(train_value))\n",
    "            \n",
    "            if show_lines and show_markers:\n",
    "                ax.plot(subset['test'], subset['mean_accuracy'], \n",
    "                        linestyle='-', marker='o',\n",
    "                        color=plot_color,\n",
    "                        label=f'Train {train_value}')\n",
    "            elif show_lines:\n",
    "                ax.plot(subset['test'], subset['mean_accuracy'], \n",
    "                        linestyle='-', \n",
    "                        color=plot_color,\n",
    "                        label=f'Train {train_value}')\n",
    "            \n",
    "            if show_markers:\n",
    "                ax.scatter(subset['test'], subset['mean_accuracy'], \n",
    "                           color=plot_color)\n",
    "    \n",
    "    ax.set_ylim((75,90))\n",
    "    ax.set_xlabel('Test')\n",
    "    ax.set_ylabel('Mean Accuracy')\n",
    "    ax.set_title(title)\n",
    "    ax.grid(True)\n",
    "    \n",
    "    if label:\n",
    "        ax.legend()\n",
    "    \n",
    "    # Add colorbar if requested\n",
    "    if add_colorbar:\n",
    "        sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "        sm.set_array([])\n",
    "        cbar = plt.colorbar(sm, ax=ax, label='Train Value')\n",
    "        cbar.set_ticks(unique_trains)\n",
    "    \n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa1a8e6-43bf-4bb6-819a-53e2d5155e1c",
   "metadata": {},
   "source": [
    "### Dev Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9bc62c38-7638-42af-aa7f-4b30c2390592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COPY\n",
    "def plot_with_shaded_errors_all(df, ax=None, title='Accuracy', label=None, shade_color='blue', alpha=0.2, show_lines=False, show_markers=False, add_colorbar=True):\n",
    "    # Check if necessary columns exist\n",
    "    required_columns = ['test', 'mean_accuracy', 'train']\n",
    "    for col in required_columns:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"Column '{col}' not found in DataFrame\")\n",
    "    \n",
    "    # Ensure mean_accuracy is numeric\n",
    "    df['mean_accuracy'] = pd.to_numeric(df['mean_accuracy'], errors='coerce')\n",
    "    \n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    unique_trains = sorted(df['train'].unique())\n",
    "    \n",
    "    # Create a color map for the gradient\n",
    "    cmap = plt.cm.viridis\n",
    "    norm = plt.Normalize(vmin=min(unique_trains), vmax=max(unique_trains))\n",
    "    \n",
    "    # Sort the dataframe by train and test\n",
    "    df_sorted = df.sort_values(['train', 'test'])\n",
    "    \n",
    "    # Create shaded region between min and max accuracies\n",
    "    min_accuracies = df_sorted.groupby('test')['mean_accuracy'].min()\n",
    "    max_accuracies = df_sorted.groupby('test')['mean_accuracy'].max()\n",
    "    ax.fill_between(min_accuracies.index, min_accuracies, max_accuracies,\n",
    "                    alpha=alpha, color='gray' if shade_color is None else shade_color, label=label)\n",
    "    \n",
    "    if show_lines or show_markers:\n",
    "        for train_value in unique_trains:\n",
    "            subset = df_sorted[df_sorted['train'] == train_value]\n",
    "            plot_color = cmap(norm(train_value))\n",
    "            \n",
    "            if show_lines and show_markers:\n",
    "                ax.plot(subset['test'], subset['mean_accuracy'], \n",
    "                        linestyle='-', marker='o',\n",
    "                        color=plot_color,\n",
    "                        label=f'Train {train_value}')\n",
    "            elif show_lines:\n",
    "                ax.plot(subset['test'], subset['mean_accuracy'], \n",
    "                        linestyle='-', \n",
    "                        color=plot_color,\n",
    "                        label=f'Train {train_value}')\n",
    "            \n",
    "            if show_markers:\n",
    "                ax.scatter(subset['test'], subset['mean_accuracy'], \n",
    "                           color=plot_color)\n",
    "    \n",
    "\n",
    "    # Set custom x-ticks and labels\n",
    "    custom_xticks = [-1, 0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
    "    custom_xlabels = ['Lévy', 'Lévy flat', '1', '2', '3', '4', '5', '6', '7', '8']\n",
    "    ax.set_xticks(custom_xticks)\n",
    "    ax.set_xticklabels(custom_xlabels)\n",
    "\n",
    "    # Rotate labels if needed for better readability\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "    \n",
    "    ax.set_ylim((75,90))\n",
    "    ax.set_xlabel('Test')\n",
    "    ax.set_ylabel('Mean Accuracy')\n",
    "    ax.set_title(title)\n",
    "    ax.grid(True)\n",
    "    \n",
    "    if label:\n",
    "        ax.legend()\n",
    "    \n",
    "    # Add colorbar if requested\n",
    "    if add_colorbar:\n",
    "        sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "        sm.set_array([])\n",
    "        cbar = plt.colorbar(sm, ax=ax, label='Train Value')\n",
    "        cbar.set_ticks(unique_trains)\n",
    "    \n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "38df5a75-a917-4528-af9a-aec9a703689e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main plotting code\n",
    "train_values = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "df = NLF_nonlevy['NLF_1'][NLF_nonlevy['NLF_1']['train'].isin(train_values)]\n",
    "df2 = NLFw_nonlevy[2][NLFw_nonlevy[2]['train'].isin(train_values)]\n",
    "df3 = NLFw_nonlevy[3][NLFw_nonlevy[3]['train'].isin(train_values)]\n",
    "dfrnn = RNN_nonlevy[RNN_nonlevy['train'].isin(train_values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4dd11267-abcf-4198-a640-0bf8d2e8287c",
   "metadata": {},
   "outputs": [],
   "source": [
    "datalevy = np.load('./NLFw/NLFw_classifier_testmetrics_testedonlevy_trainedonk.pkl', allow_pickle=True)\n",
    "datalevyeq = np.load('./NLFw/NLFw_classifier_testmetrics_testedonlevy_eq_trainedonk.pkl', allow_pickle=True)\n",
    "\n",
    "def split_NLFw_onlevy(data_dict):\n",
    "    \n",
    "    # Initialize empty dictionaries for the split data\n",
    "    data_2 = {}\n",
    "    data_3 = {}\n",
    "\n",
    "    # Split the data based on the second item of the key\n",
    "    for key, value in data_dict.items():\n",
    "        if key[1] == 2:\n",
    "            data_2[key] = value\n",
    "        elif key[1] == 3:\n",
    "            data_3[key] = value\n",
    "\n",
    "    # Create dataframes from the split data\n",
    "    NLFw_onlevy_2 = pd.DataFrame.from_dict(data_2, orient='index')\n",
    "    NLFw_onlevy_3 = pd.DataFrame.from_dict(data_3, orient='index')\n",
    "\n",
    "    return NLFw_onlevy_2, NLFw_onlevy_3\n",
    "\n",
    "NLFw_onlevy2, NLFw_onlevy3 = split_NLFw_onlevy(datalevy)\n",
    "NLFw_onlevyeq2, NLFw_onlevyeq3 = split_NLFw_onlevy(datalevyeq)\n",
    "\n",
    "NLFw_onlevy2#['accuracy'].values\n",
    "accuracies = NLFw_onlevy2['accuracy'].values * 100\n",
    "\n",
    "new_rows = pd.DataFrame({\n",
    "    'train': [1,2,3,4,5,6,7,8],\n",
    "    'test': [-1] * len(accuracies),\n",
    "    'mean_accuracy': accuracies,\n",
    "    'std_accuracy': [None] * len(accuracies)\n",
    "})\n",
    "combined_df2 = pd.concat([new_rows, df2], ignore_index=True)\n",
    "\n",
    "accuracies = NLFw_onlevyeq2['accuracy'].values * 100\n",
    "new_rows = pd.DataFrame({\n",
    "    'train': [1,2,3,4,5,6,7,8],\n",
    "    'test': [0] * len(accuracies),\n",
    "    'mean_accuracy': accuracies,\n",
    "    'std_accuracy': [None] * len(accuracies)\n",
    "})\n",
    "combined_df2 = pd.concat([new_rows, combined_df2], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "NLFw_onlevy3#['accuracy'].values\n",
    "accuracies = NLFw_onlevy3['accuracy'].values * 100\n",
    "new_rows = pd.DataFrame({\n",
    "    'train': [1,2,3,4,5,6,7,8],\n",
    "    'test': [-1] * len(accuracies),\n",
    "    'mean_accuracy': accuracies,\n",
    "    'std_accuracy': [None] * len(accuracies)\n",
    "})\n",
    "combined_df3 = pd.concat([new_rows, df3], ignore_index=True)\n",
    "\n",
    "NLFw_onlevy3#['accuracy'].values\n",
    "accuracies = NLFw_onlevyeq3['accuracy'].values * 100\n",
    "new_rows = pd.DataFrame({\n",
    "    'train': [1,2,3,4,5,6,7,8],\n",
    "    'test': [0] * len(accuracies),\n",
    "    'mean_accuracy': accuracies,\n",
    "    'std_accuracy': [None] * len(accuracies)\n",
    "})\n",
    "combined_df3 = pd.concat([new_rows, combined_df3], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce0ebc4-a345-4172-a768-0290981ea67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with subplots\n",
    "fig, axs = plt.subplots(2, 2, figsize=(20, 15)) #3, 2\n",
    "axs = axs.flatten()  # Flatten the 2D array of axes to make it easier to iterate\n",
    "\n",
    "# List of datasets and their corresponding properties\n",
    "datasets = [\n",
    "    #(LF_nonlevy['LF'], 'LF', 'green', LF_levy['LF']),\n",
    "    #(df, 'NLF', 'grey', NLF_levy['NLF_1']),\n",
    "    #(df2, 'NLF2', 'blue', NLFw_levy[2]),\n",
    "    #(df3, 'NLF3', 'red', NLFw_levy[3]),\n",
    "    #(dfrnn, 'RNN', 'purple', RNN_levy),\n",
    "    (combined_df2, 'NLF2', 'blue', NLFw_levy[2]),\n",
    "    (combined_df3, 'NLF3', 'red', NLFw_levy[3])\n",
    "]\n",
    "\n",
    "# Plot each dataset in its own subplot\n",
    "for i, (data, label, color, levy) in enumerate(datasets):\n",
    "    ax = plot_with_shaded_errors_all(\n",
    "        data, \n",
    "        ax=axs[i], \n",
    "        title=None,\n",
    "        label=label, \n",
    "        shade_color=color,\n",
    "        show_lines=0,  # Set to False if you don't want to show lines\n",
    "        show_markers=0,  # Set to False if you don't want to show markers\n",
    "        add_colorbar=0  # Set to False if you don't want to add the colorbar\n",
    "    )\n",
    "    \n",
    "    #plot_with_error_bars(levy, ax=ax, title=None)\n",
    "    # Set y-axis limits\n",
    "    ax.set_ylim(75, 100)\n",
    "axs = axs.flatten()  # This flattens the 2D array to 1D if it's 2D\n",
    "fig.delaxes(axs[-1])  # This removes the last subplot\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add a main title for the entire figure\n",
    "fig.suptitle('Comparison of Different Models', fontsize=16, y=1.02)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f667d0-4d3d-4e29-b7b0-a170431cfebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = np.load('../NLFw_classifier_testmetrics_testedonlevy_trainedlevy.pkl', allow_pickle=True) # -1\n",
    "y = np.load('../NLFw_classifier_testmetrics_testedonlevy_eq_trainedlevy.pkl', allow_pickle=True) # 0\n",
    "\n",
    "x = x[('levy', 2, 'Levy')]['accuracy'] * 100\n",
    "y = y[('levy', 2, 'Levy')]['accuracy'] *  100\n",
    "\n",
    "new_rows = pd.DataFrame({\n",
    "    'train': ['levy', 'levy'],\n",
    "    'test': [-1, 0],\n",
    "    'mean_accuracy': [x, y],  # Replace 'x' and 'y' with actual numerical values\n",
    "    'std_accuracy': [None, None]\n",
    "})\n",
    "\n",
    "# Concatenate the new rows with the existing DataFrame\n",
    "NLFw_levy[2] = pd.concat([new_rows,  NLFw_levy[2]]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abbc5e0-ae3f-4d38-ba0a-eb09cb9cec59",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load('../NLFw_classifier_testmetrics_testedonlevy_trainedlevy.pkl', allow_pickle=True) # -1\n",
    "y = np.load('../NLFw_classifier_testmetrics_testedonlevy_eq_trainedlevy.pkl', allow_pickle=True) # 0\n",
    "\n",
    "x = x[('levy', 3, 'Levy')]['accuracy'] * 100\n",
    "y = y[('levy', 3, 'Levy')]['accuracy'] *  100\n",
    "\n",
    "new_rows = pd.DataFrame({\n",
    "    'train': ['levy', 'levy'],\n",
    "    'test': [-1, 0],\n",
    "    'mean_accuracy': [x, y],  # Replace 'x' and 'y' with actual numerical values\n",
    "    'std_accuracy': [None, None]\n",
    "})\n",
    "\n",
    "# Concatenate the new rows with the existing DataFrame\n",
    "NLFw_levy[3] = pd.concat([new_rows,  NLFw_levy[3]]).reset_index(drop=True)\n",
    "NLFw_levy[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b23191-f469-4db6-8015-ad8007909101",
   "metadata": {},
   "source": [
    "### Dev End"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9685f8",
   "metadata": {},
   "source": [
    "#### (Train - Test) with error bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c4218119",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_with_error_bars_diff(df, ax=None, title='Accuracy', label=None, color=None):\n",
    "    # Check if necessary columns exist\n",
    "    required_columns = ['test', 'mean_accuracy', 'train']\n",
    "    for col in required_columns:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"Column '{col}' not found in DataFrame\")\n",
    "    \n",
    "    # Ensure mean_accuracy and std_accuracy are numeric\n",
    "    df['mean_accuracy'] = pd.to_numeric(df['mean_accuracy'], errors='coerce')\n",
    "    if 'std_accuracy' in df.columns:\n",
    "        df['std_accuracy'] = pd.to_numeric(df['std_accuracy'], errors='coerce')\n",
    "    \n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    # Calculate the difference between train and test\n",
    "    df['train_test_diff'] = df['train'] - df['test']\n",
    "    \n",
    "    unique_trains = df['train'].unique()\n",
    "    colors = plt.cm.plasma(np.linspace(0, 1, len(unique_trains)))\n",
    "    color_map = dict(zip(unique_trains, colors))\n",
    "    \n",
    "    for train_value in unique_trains:\n",
    "        subset = df[df['train'] == train_value]\n",
    "        plot_color = color if color else color_map[train_value]\n",
    "        \n",
    "        # Sort the subset by train_test_diff to ensure correct line plotting\n",
    "        subset = subset.sort_values('train_test_diff')\n",
    "        \n",
    "        # Plot the line connecting the points\n",
    "        ax.plot(subset['train_test_diff'], subset['mean_accuracy'], \n",
    "                linestyle='-', \n",
    "                color=plot_color,\n",
    "                label=label if label else f'Train {train_value}')\n",
    "        \n",
    "        # Plot the scatter points with error bars\n",
    "        ax.errorbar(subset['train_test_diff'], subset['mean_accuracy'], \n",
    "                    yerr=subset['std_accuracy'] if 'std_accuracy' in df.columns else None,\n",
    "                    fmt='o', \n",
    "                    capsize=5,\n",
    "                    capthick=1,\n",
    "                    elinewidth=1,\n",
    "                    color=plot_color)\n",
    "    \n",
    "    ax.set_ylim((76,90))\n",
    "    #ax.set_xlim(right=0)\n",
    "    ax.set_xlabel('Train-Test Difference')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_title(title)\n",
    "    ax.legend(title='Train')\n",
    "    ax.grid(True)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5035aa60",
   "metadata": {},
   "source": [
    "#### (Train - Test) with shaded regions: Individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "59ef0a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_with_shaded_errors_diff(df, ax=None, title='Accuracy', label=None, color=None, alpha=0.2, allow_legend=True):\n",
    "    # Check if necessary columns exist\n",
    "    required_columns = ['test', 'mean_accuracy', 'train']\n",
    "    for col in required_columns:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"Column '{col}' not found in DataFrame\")\n",
    "    \n",
    "    # Ensure mean_accuracy and std_accuracy are numeric\n",
    "    df['mean_accuracy'] = pd.to_numeric(df['mean_accuracy'], errors='coerce');\n",
    "    if 'std_accuracy' in df.columns:\n",
    "        df['std_accuracy'] = pd.to_numeric(df['std_accuracy'], errors='coerce')\n",
    "    \n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    # Calculate the difference between train and test\n",
    "    df['train_test_diff'] = df['train'] - df['test']\n",
    "    \n",
    "    unique_trains = df['train'].unique()\n",
    "    colors = plt.cm.plasma(np.linspace(0, 1, len(unique_trains)))\n",
    "    color_map = dict(zip(unique_trains, colors))\n",
    "    \n",
    "    for train_value in unique_trains:\n",
    "        subset = df[df['train'] == train_value]\n",
    "        plot_color = color if color else color_map[train_value]\n",
    "        \n",
    "        # Sort the subset by train_test_diff to ensure correct line plotting\n",
    "        subset = subset.sort_values('train_test_diff')\n",
    "        \n",
    "        # Plot the line\n",
    "        ax.plot(subset['train_test_diff'], subset['mean_accuracy'], \n",
    "                linestyle='-', \n",
    "                marker='o',\n",
    "                color=plot_color,\n",
    "                label=label if label else f'{train_value}')\n",
    "        \n",
    "        # Add shaded error region if std_accuracy is available\n",
    "        if 'std_accuracy' in df.columns and not subset['std_accuracy'].isna().all():\n",
    "            ax.fill_between(subset['train_test_diff'], \n",
    "                            subset['mean_accuracy'] - subset['std_accuracy'],\n",
    "                            subset['mean_accuracy'] + subset['std_accuracy'],\n",
    "                            alpha=alpha,\n",
    "                            color=plot_color)\n",
    "    \n",
    "    ax.set_ylim((75,90))\n",
    "    ax.set_xlabel('Train-Test Difference')\n",
    "    ax.set_ylabel('Mean Accuracy')\n",
    "    ax.set_title(title)\n",
    "    if allow_legend:\n",
    "        ax.legend(title='Train', ncol=2)\n",
    "    ax.grid(True)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55b7b71",
   "metadata": {},
   "source": [
    "#### (Train - Test) with shaded regions: Grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e7d90eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_with_shaded_errors_diff_all(df, ax=None, title='Accuracy', label=None, shade_color='blue', alpha=0.2, show_lines=False, show_markers=False, add_colorbar=True):\n",
    "    # Check if necessary columns exist\n",
    "    required_columns = ['test', 'mean_accuracy', 'train']\n",
    "    for col in required_columns:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"Column '{col}' not found in DataFrame\")\n",
    "    \n",
    "    # Ensure mean_accuracy is numeric\n",
    "    df['mean_accuracy'] = pd.to_numeric(df['mean_accuracy'], errors='coerce')\n",
    "    \n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    # Calculate the difference between train and test\n",
    "    df['train_test_diff'] = df['train'] - df['test']\n",
    "    \n",
    "    unique_trains = sorted(df['train'].unique())\n",
    "    \n",
    "    # Create a color map for the gradient\n",
    "    cmap = plt.cm.viridis\n",
    "    norm = plt.Normalize(vmin=min(unique_trains), vmax=max(unique_trains))\n",
    "    \n",
    "    # Sort the entire dataframe by train_test_diff\n",
    "    df_sorted = df.sort_values('train_test_diff')\n",
    "    \n",
    "    # Plot lines and markers if requested\n",
    "    if show_lines or show_markers:\n",
    "        for train_value in unique_trains:\n",
    "            subset = df_sorted[df_sorted['train'] == train_value]\n",
    "            line_color = cmap(norm(train_value))\n",
    "            \n",
    "            if show_lines and show_markers:\n",
    "                ax.plot(subset['train_test_diff'], subset['mean_accuracy'], \n",
    "                        linestyle='-', marker='o', color=line_color, \n",
    "                        label=f'Train {train_value}')\n",
    "            elif show_lines:\n",
    "                ax.plot(subset['train_test_diff'], subset['mean_accuracy'], \n",
    "                        linestyle='-', color=line_color, \n",
    "                        label=f'Train {train_value}')\n",
    "            elif show_markers:\n",
    "                ax.scatter(subset['train_test_diff'], subset['mean_accuracy'], \n",
    "                           color=line_color, label=f'Train {train_value}')\n",
    "    \n",
    "    # Create shaded region between min and max accuracies\n",
    "    min_accuracies = df_sorted.groupby('train_test_diff')['mean_accuracy'].min()\n",
    "    max_accuracies = df_sorted.groupby('train_test_diff')['mean_accuracy'].max()\n",
    "    \n",
    "    ax.fill_between(min_accuracies.index, min_accuracies, max_accuracies,\n",
    "                    alpha=alpha, color=shade_color, label=label)\n",
    "    \n",
    "    ax.set_ylim((75,90))\n",
    "    ax.set_xlabel('Train-Test Difference')\n",
    "    ax.set_ylabel('Mean Accuracy')\n",
    "    ax.set_title(title)\n",
    "    ax.grid(True)\n",
    "    \n",
    "    if label:\n",
    "        ax.legend()\n",
    "    \n",
    "    # Add colorbar if requested\n",
    "    if add_colorbar:\n",
    "        sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "        sm.set_array([])\n",
    "        cbar = plt.colorbar(sm, ax=ax, label='Train Value')\n",
    "        cbar.set_ticks(unique_trains)\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3249d29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "def plot_model_comparison(cases, train_values, figsize=(10, 6)):\n",
    "    n = len(cases)\n",
    "    rows = (n + 1) // 2  # This will give 1 row for 1-2 plots, 2 rows for 3-4 plots, etc.\n",
    "    cols = min(n, 2)     # This ensures we never have more than 2 columns\n",
    "\n",
    "    fig, axs = plt.subplots(rows, cols, figsize=figsize)\n",
    "    \n",
    "    # Ensure axs is always a 2D array\n",
    "    if n == 1:\n",
    "        axs = np.array([[axs]])\n",
    "    elif n == 2:\n",
    "        axs = axs.reshape(1, -1)\n",
    "\n",
    "    for i, (title, base) in enumerate(cases):\n",
    "        row = i // 2\n",
    "        col = i % 2\n",
    "        df = base[base['train'].isin(train_values)]\n",
    "        ax = axs[row, col]\n",
    "        plot_with_shaded_errors_diff(df, ax=ax, allow_legend=(i == 0))\n",
    "        ax.set_title(title)\n",
    "        ax.set_ylim(bottom=76)\n",
    "    \n",
    "    # Remove any unused subplots\n",
    "    for i in range(n, rows * cols):\n",
    "        row = i // cols\n",
    "        col = i % cols\n",
    "        fig.delaxes(axs[row][col] if rows > 1 else axs[col])\n",
    "    \n",
    "    # Adjust the layout and add a main title\n",
    "    plt.tight_layout()\n",
    "    #fig.suptitle('Performance Comparison Across Different Models', fontsize=16)\n",
    "    plt.subplots_adjust(top=0.93)\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Usage\n",
    "cases = [\n",
    "    #('LF', LF_nonlevy['LF']),\n",
    "    #('NLF', NLF_nonlevy['NLF_1']),\n",
    "    #('NLF 2', NLFw_nonlevy[2]),\n",
    "    #('NLF 3', NLFw_nonlevy[3]),\n",
    "    ('RNN', RNN_nonlevy)\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# To plot only specific cases:\n",
    "# cases_to_plot = [cases[0], cases[2], cases[4]]\n",
    "train_values=[2,3,4,5,6,7,8]\n",
    "plot_model_comparison(cases, train_values=train_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3579f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main plotting code\n",
    "train_values = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "df2 = NLFw_nonlevy[2][NLFw_nonlevy[2]['train'].isin(train_values)]\n",
    "df3 = NLFw_nonlevy[3][NLFw_nonlevy[3]['train'].isin(train_values)]\n",
    "dfrnn = RNN_nonlevy[RNN_nonlevy['train'].isin(train_values)]\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig, axs = plt.subplots(2, 2, figsize=(20, 16))\n",
    "axs = axs.flatten()  # Flatten the 2D array of axes to make it easier to iterate\n",
    "\n",
    "# List of datasets and their corresponding properties\n",
    "datasets = [\n",
    "    (LF_nonlevy['LF'], 'LF', 'green'),\n",
    "    (df2, 'NLF2', 'blue'),\n",
    "    (df3, 'NLF3', 'red'),\n",
    "    (dfrnn, 'RNN', 'purple')\n",
    "]\n",
    "\n",
    "# Plot each dataset in its own subplot\n",
    "for i, (data, label, color) in enumerate(datasets):\n",
    "    ax = plot_with_shaded_errors_diff_all(\n",
    "        data, \n",
    "        ax=axs[i], \n",
    "        title=None,\n",
    "        label=label, \n",
    "        shade_color=color,\n",
    "        show_lines=False,  # Set to False if you don't want to show lines\n",
    "        show_markers=False,  # Set to False if you don't want to show markers\n",
    "        add_colorbar=False  # Set to False if you don't want to add the colorbar\n",
    "    )\n",
    "    \n",
    "    # Set y-axis limits\n",
    "    ax.set_ylim(75, 90)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add a main title for the entire figure\n",
    "fig.suptitle('Comparison of Different Models', fontsize=16, y=1.02)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9600b727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main plotting code\n",
    "train_values = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "df = NLF_nonlevy['NLF_1'][NLF_nonlevy['NLF_1']['train'].isin(train_values)]\n",
    "df2 = NLFw_nonlevy[2][NLFw_nonlevy[2]['train'].isin(train_values)]\n",
    "df3 = NLFw_nonlevy[3][NLFw_nonlevy[3]['train'].isin(train_values)]\n",
    "dfrnn = RNN_nonlevy[RNN_nonlevy['train'].isin(train_values)]\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig, axs = plt.subplots(3, 2, figsize=(20, 15))\n",
    "axs = axs.flatten()  # Flatten the 2D array of axes to make it easier to iterate\n",
    "\n",
    "# List of datasets and their corresponding properties\n",
    "datasets = [\n",
    "    (LF_nonlevy['LF'], 'LF', 'green', LF_levy['LF']),\n",
    "    (df, 'NLF', 'grey', NLF_levy['NLF_1']),\n",
    "    (df2, 'NLF2', 'blue', NLFw_levy[2]),\n",
    "    (df3, 'NLF3', 'red', NLFw_levy[3]),\n",
    "    (dfrnn, 'RNN', 'purple', RNN_levy)\n",
    "]\n",
    "\n",
    "# Plot each dataset in its own subplot\n",
    "for i, (data, label, color, levy) in enumerate(datasets):\n",
    "    ax = plot_with_shaded_errors_all(\n",
    "        data, \n",
    "        ax=axs[i], \n",
    "        title=None,\n",
    "        label=label, \n",
    "        shade_color=color,\n",
    "        show_lines=0,  # Set to False if you don't want to show lines\n",
    "        show_markers=0,  # Set to False if you don't want to show markers\n",
    "        add_colorbar=0  # Set to False if you don't want to add the colorbar\n",
    "    )\n",
    "    plot_with_error_bars(levy, ax=ax, title=None)\n",
    "    # Set y-axis limits\n",
    "    ax.set_ylim(75, 90)\n",
    "axs = axs.flatten()  # This flattens the 2D array to 1D if it's 2D\n",
    "fig.delaxes(axs[-1])  # This removes the last subplot\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add a main title for the entire figure\n",
    "fig.suptitle('Comparison of Different Models', fontsize=16, y=1.02)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c55f279-2b66-4759-addf-e15cf8c6439f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ax = plot_with_error_bars(RNN_levy, label='Levy', color='grey')\n",
    "#plot_with_error_bars(RNN_levy_eqldistr, ax=ax, label='Levy equal dist k', color='salmon')\n",
    "# Plotting the second dataframe on the same figure\n",
    "plot_with_error_bars(RNN_nonlevy,  title='$RNN$')\n",
    "plt.ylim(75,90)\n",
    "#plt.grid()\n",
    "plt.savefig('Fig2D1.svg', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25808f22-009d-42c7-a63c-5a34eea40c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "aax = plot_with_error_bars(RNN_levy, label='RNN Levy', color='salmon')\n",
    "#plot_with_error_bars(RNN_nonlevy[RNN_nonlevy['train']==3], label='RNN train 3', color='red')\n",
    "#\n",
    "plot_with_error_bars(NLFw_levy[3], ax=aax, label='NLF3 Levy', color='grey')\n",
    "#plot_with_error_bars(NLFw_levy[2], ax=aax, label='NLF2 Levy', color='steelblue')\n",
    "#plot_with_error_bars(NLFw_levy_eqldistr[2], ax=aax, label='NLF2 Levy eq', color='b')\n",
    "#plot_with_error_bars(NLFw_levy_eqldistr[3], ax=aax, label='NLF3 Levy eq', color='y')\n",
    "\n",
    "\n",
    "#plot_with_error_bars(NLFw_nonlevy[3][NLFw_nonlevy[3]['train']==3], ax=aax, label='NLF3 train 3', color='black')\n",
    "#plot_with_error_bars(NLFw_nonlevy[2][NLFw_nonlevy[2]['train']==3], ax=aax, label='NLF2 train 3', color='green')\n",
    "##plt.ylim(82,85)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba99cb20-3087-4e0f-8831-5842ab2d8d54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ws = 3\n",
    "axx = plot_with_error_bars(NLFw_nonlevy[ws],title='$NLF_3$')\n",
    "plt.ylim(75,90)\n",
    "#plt.grid()\n",
    "plt.savefig('Fig2C1.svg', dpi=300)\n",
    "#plot_with_error_bars(NLFw_levy_eqldistr[ws], ax=axx, label='Levy equal dist k', color='salmon')\n",
    "#plot_with_error_bars(NLFw_levy[ws], ax=axx, title=f'NLF {ws}', color='grey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b3e0cd-9025-4437-83ee-6e650d774a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = 2\n",
    "axx = plot_with_error_bars(NLFw_nonlevy[ws], title='$NLF_2$')\n",
    "plt.ylim(75,90)\n",
    "#plt.grid()\n",
    "plt.savefig('Fig2B1.svg', dpi=300)\n",
    "#plot_with_error_bars(NLFw_levy_eqldistr[ws], ax=axx, label='Levy equal dist k', color='salmon')\n",
    "#plot_with_error_bars(NLFw_levy[ws], ax=axx, title=f'NLF {ws}', color='grey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccdb14a-5a79-4013-9e95-d7222c1a5b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = 'NLF_1'\n",
    "axx = plot_with_error_bars(NLF_nonlevy[ws])\n",
    "plot_with_error_bars(NLF_levy_eqldistr[ws], ax=axx, label='Levy equal dist k', color='salmon')\n",
    "plot_with_error_bars(NLF_levy[ws], ax=axx, title=f'{ws}', color='grey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed6243c-9368-469c-b607-4459208d79a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = 'LF'\n",
    "axx = plot_with_error_bars(LF_nonlevy[ws])\n",
    "plot_with_error_bars(LF_levy_eqldistr[ws], ax=axx, label='Levy equal dist k', color='salmon')\n",
    "plot_with_error_bars(LF_levy[ws], ax=axx, title=f'{ws}', color='grey')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7efcae-892c-4f26-b8fb-c8856428d42e",
   "metadata": {},
   "source": [
    "#### RNN std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a9e845-a1e3-4ff7-b6df-cc10b0c5a6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set your desired threshold\n",
    "threshold = 0.6  # Adjust this value as needed\n",
    "\n",
    "# Create a new DataFrame with the filtered rows and the additional 'difference' column\n",
    "result = RNN_nonlevy[RNN_nonlevy['std_accuracy'] > threshold].copy()\n",
    "result['difference'] = result['train'] - result['test']\n",
    "\n",
    "# Sort the results by 'std_accuracy' in descending order\n",
    "result = result.sort_values('std_accuracy', ascending=False)\n",
    "\n",
    "# Select and reorder the columns as desired\n",
    "columns_to_show = ['train', 'test', 'difference', 'mean_accuracy', 'std_accuracy']\n",
    "result = pd.DataFrame(result[columns_to_show])\n",
    "\n",
    "\n",
    "plt.scatter(result['std_accuracy'], result['difference'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f39acb-5f97-45c0-ad46-9d5088cc24fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "\n",
    "def generate_matrices(df):\n",
    "    M = np.zeros((8,8))\n",
    "    E = np.zeros((8,8))\n",
    "    for i in range(8):\n",
    "        for j in range(8):\n",
    "            M[i,j] = df[(df['train']==i+1) & (df['test']==j+1)]['mean_accuracy'].values[0]\n",
    "            E[i,j] = df[(df['train']==i+1) & (df['test']==j+1)]['std_accuracy'].values[0]\n",
    "    return M, E\n",
    "\n",
    "def norm(M, E=None, title='Alg', do_return=False):\n",
    "    # Create a plasma-like colormap\n",
    "    colors = plt.cm.plasma(np.linspace(0, 1, 8))\n",
    "    plt.figure(figsize=(10,6))\n",
    "    for train in range(1,9):\n",
    "        test = np.arange(1,9)\n",
    "        x = train - test\n",
    "        y = M[train-1, :] - M.max(axis=0)\n",
    "        \n",
    "        \n",
    "        # Plot the line with plasma colors\n",
    "        \n",
    "        plt.plot(x, y, 'o-', label=f'{train}', color=colors[train-1])\n",
    "        \n",
    "        # Add shaded region for error with plasma colors\n",
    "        #if E:\n",
    "        # Release for RNN\n",
    "        error = E[train-1, :]\n",
    "        plt.fill_between(x, y-error, y+error, alpha=0.2, color=colors[train-1])\n",
    "        \n",
    "    if title == '$NLF_2$':\n",
    "        plt.legend(title = 'Train', ncol=2)\n",
    "    plt.xlabel('Train - Test')\n",
    "    plt.ylabel('$\\Delta$ Accuracy')\n",
    "    plt.vlines(0, -8, 1, color='grey', linestyle='--', linewidth=3)\n",
    "    plt.title(f'{title}')\n",
    "    #plt.grid()\n",
    "    plt.ylim(-8,1)\n",
    "    if do_return:\n",
    "        return M, E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dc4390-00bd-48c5-877c-5cdb08511c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "M, _ = generate_matrices(NLFw_nonlevy[3])\n",
    "norm(M, title='$NLF_3$')\n",
    "plt.savefig('Fig2C2.svg', dpi=300)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51a6182-f1fd-4706-b4fc-bc4933da945f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function\n",
    "M, _ = generate_matrices(NLFw_nonlevy[2])\n",
    "norm(M, title='$NLF_2$')\n",
    "plt.savefig('Fig2B2.svg', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\"\"\"\n",
    "M, _ = generate_matrices(NLFw_nonlevy[3])\n",
    "norm(M, 'NLF 3')\n",
    "plt.show()\n",
    "\n",
    "M, _ = generate_matrices(RNN_nonlevy)\n",
    "norm(M, 'RNN')\n",
    "plt.show()\n",
    "\n",
    "norm(NLF_nonlevy['NLF_1'], 'NLF 2')\n",
    "plt.show()\n",
    "\n",
    "norm(LF_nonlevy['LF'], 'NLF 2')\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b854ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function\n",
    "M, E = generate_matrices(RNN_nonlevy)\n",
    "norm(M, E, title='$RNN$')\n",
    "plt.savefig('Fig2D2.svg', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43eda129",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "M, _ = generate_matrices(RNN_nonlevy)\n",
    "N = M - M.max(axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252ddcc7",
   "metadata": {},
   "source": [
    "### Overall winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7e7f55-5380-477c-9930-47e32cefff8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_matrices(RNN_nonlevy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "002cf963-d28d-4729-be49-e8f6ebd7d42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_matrices(df):\n",
    "    M = np.zeros((8,8))\n",
    "    E = np.zeros((8,8))\n",
    "    for i in range(8):\n",
    "        for j in range(8):\n",
    "            M[i,j] = df[(df['train']==i+1) & (df['test']==j+1)]['mean_accuracy'].values[0]\n",
    "            E[i,j] = df[(df['train']==i+1) & (df['test']==j+1)]['std_accuracy'].values[0]\n",
    "    return M, E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dc73e24c-f460-4a84-a932-47385e46a41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_levytrained = np.load('./RNN_levytrained_alltest.npy', allow_pickle=True).item()\n",
    "RNN_levyeqtrained = np.load('./RNN_levyeqtrained_alltest.npy', allow_pickle=True).item()\n",
    "RNN_ktrained_levytested = np.load('./RNN_testonlevy_trainonk.npy', allow_pickle=True).item()\n",
    "RNN_ktrained_levyeqtested = np.load('./RNN_testonlevyeq_trainonk.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2f780775-56f9-4ae2-903e-fcbb6fe8ecac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortmean(data):\n",
    "    dict_arrays = {k: np.array(v) if not isinstance(v, np.ndarray) else v for k, v in data.items()}\n",
    "    sorted_means = {k: np.mean(dict_arrays[k]) for k in sorted(dict_arrays.keys())}\n",
    "    return sorted_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "140b4c8e-e893-4afe-b9d5-964cf371fd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_levytrained = sortmean(RNN_levytrained)\n",
    "RNN_levyeqtrained = sortmean(RNN_levyeqtrained)\n",
    "RNN_ktrained_levytested = sortmean(RNN_ktrained_levytested)\n",
    "RNN_ktrained_levyeqtested = sortmean(RNN_ktrained_levyeqtested)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "40658760-9057-42fa-a46e-2f8b0f6fb882",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros([10,10])\n",
    "X[2:,2:], _ = generate_matrices(RNN_nonlevy)\n",
    "X[0] = list(RNN_levytrained.values())\n",
    "X[1] = list(RNN_levyeqtrained.values())\n",
    "X[2:10,0] = list(RNN_ktrained_levytested.values())\n",
    "X[2:10,1] = list(RNN_ktrained_levyeqtested.values())\n",
    "RNN_all = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2256057a-7ece-453b-8b0b-3fabedafae98",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load('./NLF2_levytrained_alltest.npy', allow_pickle=True)\n",
    "b = np.load('./NLF2_levyeqtrained_alltest.npy', allow_pickle=True)\n",
    "c = np.load('./NLF2_ktrained_alltest.npy', allow_pickle=True)[:8][:, 2] # Levy\n",
    "d = np.load('./NLF2_ktrained_alltest.npy', allow_pickle=True)[8:16][:, 2] # Levy flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0d0f6e4c-f3a9-4645-8bdd-0c97099b4f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.zeros([10,10])\n",
    "Y[2:,2:], _ = generate_matrices(NLFw_nonlevy[2])\n",
    "Y[0] = a\n",
    "Y[1] = b\n",
    "Y[2:10,0] = c\n",
    "Y[2:10,1] = d\n",
    "NLF2 = Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9add9287-6a5f-484a-aab7-766e72bea024",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load('./NLF3_levytrained_alltest.npy', allow_pickle=True)\n",
    "b = np.load('./NLF3_levyeqtrained_alltest.npy', allow_pickle=True)\n",
    "c = np.load('./NLF3_ktrained_alltest.npy', allow_pickle=True)[:8][:, 2] # Levy\n",
    "d = np.load('./NLF3_ktrained_alltest.npy', allow_pickle=True)[8:16][:, 2] # Levy flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7327b5a8-ab92-4006-ae05-ba31acc6019f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.zeros([10,10])\n",
    "Z[2:,2:], _ = generate_matrices(NLFw_nonlevy[3])\n",
    "Z[0] = a\n",
    "Z[1] = b\n",
    "Z[2:10,0] = c\n",
    "Z[2:10,1] = d\n",
    "NLF3 = Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "681e7d17-acf2-45d6-80d7-a8cf6cddedf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "M0, _ = generate_matrices(LF_nonlevy['LF'])\n",
    "N0 = M0 #- M2.max(axis=0)\n",
    "\n",
    "M1, _ = generate_matrices(NLF_nonlevy['NLF_1'])\n",
    "N1 = M1 #- M2.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cc041ce2-b54a-45a2-b1cd-e4e9b1b223ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "M2, _ = generate_matrices(NLFw_nonlevy[2])\n",
    "#W2 = M2 - M2.min(axis=0)\n",
    "\n",
    "M3, _ = generate_matrices(NLFw_nonlevy[3])\n",
    "#N3 = M3# - M3.max(axis=0)\n",
    "\n",
    "Mr, _ = generate_matrices(RNN_nonlevy)\n",
    "#Nr = Mr# - Mr.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "83564e94-a115-471f-bfd7-4303f37363d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_acc = min(M1.min(), M2.min(), M3.min())\n",
    "max_acc = max(M1.max(), M2.max(), M3.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "699c1876-deca-40d5-bf5d-80f5274d6ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = M2 - min_acc\n",
    "W3 = M3 - min_acc\n",
    "Wr = Mr - min_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bd8c90-58c6-4fd8-a188-1f4857a523e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_matrices = [N1, N3, Nr]\n",
    "plot_algorithm_performance(accuracy_matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "22360952-ef2f-4b45-a996-aec5a38e501b",
   "metadata": {},
   "outputs": [],
   "source": [
    "M, _ = generate_matrices(NLFw_nonlevy[3])\n",
    "weight = M - M.min()\n",
    "#sat = weight /  # saturation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5cd04abc-6730-4e14-a334-3fa1fe7ef26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.patches import Circle, Wedge\n",
    "import colorsys\n",
    "\n",
    "def get_global_min_max(accuracy_matrices):\n",
    "    \"\"\"Get global minimum and maximum accuracies across all matrices.\"\"\"\n",
    "    all_values = [acc for matrix in accuracy_matrices for row in matrix for acc in row]\n",
    "    return min(all_values), max(all_values)\n",
    "\n",
    "def calculate_radius_and_saturations(accuracies, global_min, global_max):\n",
    "    \"\"\"\n",
    "    Calculate radius and saturations using global min/max values.\n",
    "    \n",
    "    Radius formula: (Acc(alg, tr, te) - global_min) / (global_max - global_min)\n",
    "    \"\"\"\n",
    "    # Handle edge case where global min equals global max\n",
    "    if global_max == global_min:\n",
    "        return [1] * len(accuracies), [1/3] * len(accuracies)\n",
    "    \n",
    "    # Calculate radii using global normalization\n",
    "    radii = [(acc - global_min) / (global_max - global_min) for acc in accuracies]\n",
    "    \n",
    "    # Calculate saturations (local normalization for visual distinction)\n",
    "    min_acc = min(accuracies)\n",
    "    weights = [acc - min_acc for acc in accuracies]\n",
    "    weight_sum = sum(weights)\n",
    "    \n",
    "    if weight_sum == 0:\n",
    "        saturations = [1/3] * len(accuracies)  # Equal saturations if all values are equal\n",
    "    else:\n",
    "        saturations = [weight/weight_sum for weight in weights]\n",
    "    \n",
    "    # Ensure minimum radius for visibility\n",
    "    min_radius = 0.2  # Minimum radius for visibility\n",
    "    radii = [max(r, min_radius) for r in radii]\n",
    "    \n",
    "    return radii, saturations\n",
    "\n",
    "def adjust_color_saturation(base_color, saturation):\n",
    "    \"\"\"Adjust the saturation of a hex color.\"\"\"\n",
    "    rgb = tuple(int(base_color.lstrip('#')[i:i+2], 16)/255 for i in (0, 2, 4))\n",
    "    hsv = colorsys.rgb_to_hsv(*rgb)\n",
    "    min_saturation = 0.1\n",
    "    max_saturation = 1\n",
    "    adjusted_saturation = min_saturation + (max_saturation - min_saturation) * saturation\n",
    "    new_hsv = (hsv[0], adjusted_saturation, hsv[2])\n",
    "    rgb = colorsys.hsv_to_rgb(*new_hsv)\n",
    "    return '#{:02x}{:02x}{:02x}'.format(int(rgb[0]*255), int(rgb[1]*255), int(rgb[2]*255))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7003bf-0985-44d3-be46-e1f14afd7b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_algorithm_performance(accuracy_matrices, show_values=False, value_format='.2f', \n",
    "                             value_size=8, value_color='grey'):\n",
    "    \"\"\"\n",
    "    Plot algorithm performance comparison with globally normalized radii.\n",
    "    \"\"\"\n",
    "    n_scenarios = len(accuracy_matrices[0])\n",
    "    fig, axs = plt.subplots(n_scenarios, n_scenarios, figsize=(1.*n_scenarios, 1.*n_scenarios))\n",
    "    \n",
    "    #base_colors = ['#FFB6C1', '#ADD8E6', '#DDA0DD']  # Pastel Pink, Pastel Blue, Pastel Violet\n",
    "    base_colors = [color_NLF2, color_NLF3, color_RNN] #['#DAA520', '#b5c9b5', '#9b7aa1'] \n",
    "    algorithm_names = ['NLF 2', 'NLF 3', 'RNN']\n",
    "    \n",
    "    # Get global min and max for normalization\n",
    "    global_min, global_max = get_global_min_max(accuracy_matrices)\n",
    "    \n",
    "    for i in range(n_scenarios):\n",
    "        for j in range(n_scenarios):\n",
    "            ax = axs[i, j]\n",
    "            accuracies = [matrix[i][j] for matrix in accuracy_matrices]\n",
    "            radii, saturations = calculate_radius_and_saturations(accuracies, global_min, global_max)\n",
    "            \n",
    "            # Scale up the radii\n",
    "            radii = [r * 1.5 for r in radii]  # Increase radius by 50%\n",
    "            \n",
    "            start_angle = 0\n",
    "            for k, (accuracy, radius, saturation) in enumerate(zip(accuracies, radii, saturations)):\n",
    "                end_angle = start_angle + 360 * (1/3)\n",
    "                color = adjust_color_saturation(base_colors[k], saturation)\n",
    "                \n",
    "                wedge = Wedge((0, 0), radius, start_angle, end_angle, fc=color, ec='none')\n",
    "                ax.add_artist(wedge)\n",
    "                \n",
    "                if show_values:\n",
    "                    angle_rad = np.radians(start_angle + (end_angle - start_angle)/2)\n",
    "                    text_radius = radius * 0.5\n",
    "                    x = text_radius * np.cos(angle_rad)\n",
    "                    y = text_radius * np.sin(angle_rad)\n",
    "                    \n",
    "                    value_text = f\"{accuracy:{value_format}}\"\n",
    "                    ax.text(x, y, value_text, ha='center', va='center', \n",
    "                           fontsize=value_size, color=value_color,\n",
    "                           rotation=np.degrees(angle_rad) % 360 - 90)\n",
    "                \n",
    "                start_angle = end_angle\n",
    "            \n",
    "            # Expand plot limits to accommodate larger radii\n",
    "            ax.set_xlim(-1.65, 1.65)  # Increased from ±1.1\n",
    "            ax.set_ylim(-1.65, 1.65)\n",
    "            ax.axis('off')\n",
    "    \n",
    "    # Define scenario names\n",
    "    test_names = ['Lévy', 'Uniform'] + [f'{i}' for i in range(1, 9)]\n",
    "    train_names = ['Lévy', 'Uniform'] + [f'{i}' for i in range(1, 9)]\n",
    "    \n",
    "    # Set column titles (test scenarios)\n",
    "    for j in range(n_scenarios):\n",
    "        axs[0, j].set_title(test_names[j], fontsize=15, color='black')\n",
    "    \n",
    "    # Set row labels (train scenarios)\n",
    "    for i in range(n_scenarios):\n",
    "        axs[i, 0].text(-2.25, 0, train_names[i], rotation=90, va='center', ha='right', fontsize=15, color='black')\n",
    "    \n",
    "    # Add x and y axis labels - moved 'Test' label above the plot\n",
    "    fig.text(0.5, 1, 'Test', ha='center', va='center', fontsize=20)\n",
    "    fig.text(-0.0, 0.5, 'Train', va='center', ha='center', rotation=90, fontsize=20)\n",
    "    \n",
    "    legend_elements = [plt.Rectangle((0, 0), 1, 1, fc=color, ec='none') for color in base_colors]\n",
    "    fig.legend(legend_elements, algorithm_names, loc='upper right', bbox_to_anchor=(0.97, 1.01), \n",
    "              fontsize=10, frameon=False, ncol=3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig, axs\n",
    "\n",
    "# With white values\n",
    "accuracy_matrices = [Y, Z, X]\n",
    "reduced = [Y[2:,2:], Z[2:,2:], X[2:,2:]]\n",
    "original = [M2, M3, Mr]\n",
    "plot_algorithm_performance(accuracy_matrices, show_values=0, value_color='white')\n",
    "#plt.title('Relative saturations: normalised weights')\n",
    "plt.savefig('Fig4.svg', dpi=300, bbox_inches='tight', pad_inches=0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nest3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
